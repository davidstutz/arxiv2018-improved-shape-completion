\section{Conclusion}
\label{sec:conclusion}

In this paper, we presented a novel, weakly-supervised learning-based approach to 3D shape completion from sparse and noisy point cloud observations. We used a (denoising) variational auto-encoder \citep{Im2017AAAI,Kingma2014ICLR} to learn a latent space of shapes for one or multiple object categories using synthetic data from ShapeNet \citep{Chang2015ARXIV} or ModelNet \citep{Wu2015CVPR}. Based on the learned generative model, \ie, decoder, we formulated 3D shape completion as a maximum likelihood problem. In a second step, we then fixed the learned generative model and trained a new recognition model, \ie encoder, to amortize, \ie \emph{learn}, the maximum likelihood problem. Thus, our {\bf Amortized Maximum Likelihood (\AML)} approach to 3D shape completion can be trained in a weakly-supervised fashion. Compared to related data-driven approaches, \eg, \citep{Rock2015CVPR,Haene2014CVPR,Li2015CGF,Engelmann2016GCPR,Engelmann2017WACV,Nan2012TG,Bao2013CVPR,Dame2013CVPR,Ngyuen2016CVPR}, our approach offers fast inference at test time; in contrast to other learning-based approaches, \eg, \citep{Riegler2017THREEDV,Smith2017ARXIV,Dai2017CVPRa,Sharma2016ARXIV,Fan2017CVPR,Rezende2016ARXIV,Yang2018ARXIVb,Wang2017ICCV,Varley2017IROS,Han2017ICCV}, we do not require full supervision during training. Both characteristics render our approach useful for robotic scenarios where full supervision is often not available such as in autonomous driving, \eg, on KITTI \citep{Geiger2012CVPR}, or indoor robotics, \eg, on \Kinect \citep{Yang2018ARXIVb}.

On two newly created synthetic shape completion benchmarks, derived from ShapeNet's cars and ModelNet10, as well as on real data from KITTI and, we demonstrated that \AML outperforms related data-driven approaches \citep{Engelmann2016GCPR,Gupta2015CVPR} while being significantly faster. We further showed that \AML is able to compete with fully-supervised approaches \citep{Dai2017CVPRa}, both quantitatively and qualitatively, while using only $3-10\%$ supervision or less. In contrast to \citep{Rock2015CVPR,Haene2014CVPR,Li2015CGF,Engelmann2016GCPR,Engelmann2017WACV,Nan2012TG,Bao2013CVPR,Dame2013CVPR}, we additionally showed that \AML is able to generalize across object categories without category supervision during training. On \Kinect, we also demonstrated that our \AML approach is able to generalize from very few training examples. In contrast to \citep{Girdhar2016ECCV,Liu2017ARXIV,Sharma2016ARXIV,Wu2015CVPR,Dai2017CVPRa,Firman2016CVPR,Han2017ICCV,Fan2017CVPR}, we considered resolutions up to $48 \ntimes 108 \ntimes 48$ and $64^3$ voxels as well as significantly sparser observations. Overall, our experiments demonstrate two key advantages of the proposed approach: significantly reduced runtime and increased performance compared to data-driven approaches showing that amortizing inference is highly effective.

In future work, we would like to address several aspects of our \AML approach. First, the shape prior is essential for weakly-supervised shape completion, as also noted by \cite{Gwak2017ARXIV}. However, training expressive generative models in 3D is still difficult. Second, larger resolutions imply significantly longer training times; alternative shape representations and data structures such as point clouds \citep{Qi2017CVPR,Qi2017NIPS,Fan2017CVPR} or octrees \citep{Riegler2017CVPR,Riegler2017THREEDV,Haene2017ARXIV} might be beneficial. Finally, jointly tackling pose estimation and shape completion seems promising~\citep{Engelmann2016GCPR}.